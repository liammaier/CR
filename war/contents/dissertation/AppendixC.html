<!DOCTYPE html>
<html lang="en-US">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

<head>

	<title>Griffith Dissertation Appendix B</title>
	<link rel="stylesheet" type="text/css" href="dissertation.css" />
	
</head>

<body>

	<div class="dissertation container">

		<section class="section" data-number="0" data-name="Appendix C">

			<h1>
				APPENDIX C
			</h1>

			<h1>
				DEVELOPMENT AND VALIDATION OF SVT
			</h1>

			<p>
				The researcher and research assistants developed the sentence verification tests 
				(SVTs) using the following procedure adapted from Royer
				<span class="cite-use" data-ref="0">(1975)</span>.
				The original text from 
				each chapter was divided into T-units during the process of equating passages. Two 
				researchers coded each T-unit as either autonomous or non-autonomous. Autonomous
				Tunits could be understood independently of the rest of the text; for example: “Mankind 
				are the only beings who may be said to have gained an absolute control over the 
				production of food.” Non-autonomous c-units required reference to the text to be 
				understood; for example: “This led to an increase in the food supply, which in turn 
				supported an increase in population, resulting in the development of settled villages.”
			</p>

			<p>
				Paraphrase sentences were developed based on autonomous T-units. Almost all 
				content words within the T-units were replaced with synonyms. Using the example 
				above, a sample of a paraphrase sentence is: <em>“Humans</em> are the only <em>creatures</em> who may be 
				said to have <em>achieved complete power</em> over the <em>creation</em> of food.” Local cohesion 
				statements were developed based on non-autonomous T-units. Content words within the 
				T-units were also replaced with synonyms but in addition were made explicit by 
				integrating nearby content containing the implied information: “<em>The transition from 
				hunting and gathering to farming</em> led to a an <em>increase</em> in the food supply, which in turn 
				<em>sustained</em> a <em>growing population, leading</em> to the <em>emergence</em> of settled villages.” Global 
				cohesion statements were developed based on the chapter maps generated earlier. As part 
				of that process, two to three statements were generated for each section of the text that 
				summarized the key ideas of that section. Construction of those statements typically 
			</p>

			<div class="pagebreak">
				<span class="pageNumber">
					86
				</span>
			</div>

<!-- Page 87 -->

			<p class="noIndent">
				involved synthesizing several sentences into an overarching idea. For example, based on 
				section three of the Chapter A, a global statement was: <em>Today’s anthropologists question 
				whether agriculture is really a better way of life than hunting-gathering.</em>
			</p>

			<p>
				Two versions of each item were developed for each sentence type: a true sentence 
				and a false sentences. True sentences were developed first. False sentences were then 
				constructed based on the each true statement. False sentences were developed by first 
				trying to replace at least one content word with an antonym. If an antonym was not 
				available, content words were replaced by a competing concept from the text. For 
				example: Humans <em>like many other creatures</em> are said to have achieved complete power 
				over the creation of food.
			</p>

			<p>
				The first and second researchers each produced half of the paraphrase items for 
				each passage. The first and third researchers both produced local coherence items and 
				global coherence items. All items were then pooled together. The researchers then 
				independently read each item and rated each as either clear or unclear. Occasionally, 
				substituting content words with synonyms resulted in awkward sentences; the purpose of 
				the review was to eliminate unclear items. 
			</p>

			<p>
				The test items were piloted by asking thirty undergraduate volunteers to read the 
				chapters and then complete the sentence verification tasks, consisting of sixty test items 
				per chapter. In addition, four volunteers completed the sentence verification task without 
				reading the chapter to help eliminate items that could be easily answered based on 
				background knowledge only. See Table E.1 for a summary of results. Mean scores 
				showed a lower performance overall for Chapter B compared to Chapter A for all 
				volunteers. Accuracy rates of items from each chapter were reviewed and compared to 
			</p>

			<div class="pagebreak">
				<span class="pageNumber">
					87
				</span>
			</div>

<!-- Page 88 -->

			<p class="noIndent">
				identify items that could be eliminated. To improve validity, items that had an accuracy 
				rate of 100% by the volunteers who did not read the chapters were eliminated from both 
				tests. Items that were missed by 90% or more of the volunteers were also reviewed to 
				eliminate items that may have been unclear. 
			</p>

			<p>
				Remaining items were categorized by their original type: paraphrase, local 
				cohesion and global cohesion to compare performance between statement types. 
				Accuracy of paraphrase items was significantly higher for both chapters compared to 
				both cohesion items; however, no difference was noted between local and global 
				cohesion items. The two cohesion items were both constructed to reflect inferences 
				generated at different levels of the text: locally based on nearby text and globally based 
				on the overall text. 
			</p>

			<p>
				To equate difficulty, the distributions of accuracy of individual items from both 
				chapters were compared (See Table E.2). For the Chapter A, items answered correctly by 
				80% of the volunteers (who read the chapter) were eliminated to increase the difficulty of 
				that test. Items from the Social Complexity chapter answered correctly by 20% or fewer 
				of the volunteers were also eliminated to decrease the difficulty of that test. Finally, 
				remaining items were reviewed to eliminate redundant questions and to ensure an equal 
				number of paraphrase and inference items were represented. Ultimately thirty items were 
				selected for each chapter, ten from each category. For the analysis, number of accurate 
				response for each item type were calculated.
			</p>

			<h2>
				Pilot Study and Validation
			</h2>

			<p>
				Prior to the dissertation study, a pilot study was conducted to evaluate the SVTs 
				to ensure they were valid and reliable. Tools are considered valid to the degree they 
			</p>

			<div class="pagebreak">
				<span class="pageNumber">
					88
				</span>
			</div>

<!-- Page 89 -->

			<p class="noIndent">
				measure what they purport to measure and reliable when they yield consistent results 
				under similar conditions
				<span class="cite-use" data-ref="0">(American Educational Research Association (AERA), American Psychological Association (APA), & National Council on Measurement in Education (NCME), 1999;</span>
				<span class="cite-use" data-ref="0">Shipley & McAfee, 2009)</span>.
			</p>

			<p>
				The foundation for the validity of the tests was established by developing a type 
				of instrument that is widely used and has already been validated in the research 
				community to evaluate reading comprehension , and that aligns with the theoretical 
				constructs that undergird this study. The foundation for reliability was established by 
				drawing from existing operationalized procedures for developing items
				<span class="cite-use" data-ref="0">(Royer, 1975)</span>, 
				and by evaluating the fidelity of item development through ongoing consultations with 
				research team members. 
			</p>

			<p>
				The objectives of the pilot study were to further establish reliability by insuring 
				the total scores and subtest scores by sentence type were: (1) characterized by normal 
				distributions, (2) equivalent in overall level of difficulty, and (3) equivalent in the 
				distribution of test items by difficulty, sentence type and content location in the chapters. 
				Additional objectives were to further establish validity by: (1) comparing performance on 
				the tests to external measures known to correlate with reading comprehension ability, and 
				(2) insuring performance on the tests were not passage independent (i.e. participants who 
				read the chapter would do better than those who did not). 
			</p>

			<p>
				<strong>Pilot methods.</strong> To meet these objectives, currently enrolled undergraduate 
				students were recruited to read the two test chapters and take each sentence verification 
				test, as described in more depth in the two sections below. Results on the two tests were 
				initially evaluated by examining the distributions of scores and by comparing 
			</p>

			<div class="pagebreak">
				<span class="pageNumber">
					89
				</span>
			</div>

<!-- Page 90 -->
			
			<p class="noIndent">
				participants’ performance as measured by percent accurate to provide preliminary support 
				for equivalency and identify problems. Next, results were evaluated by comparing the 
				accuracy and distribution of individual test items across the two tests. Item accuracy was 
				considered an approximation of level of difficulty. Item sets were reduced to improve 
				equivalency of distribution and to shorten the overall tests. Correlations between the two 
				trimmed tests were calculated. As a final step, a regression analysis was conducted to 
				evaluate whether results on a vocabulary measure given as part of the pilot test predicted 
				performance on the sentence verification tests. 
			</p>

			<p>
				In the following section the pilot test is described in more detail. The next section 
				describes the participants including how they were recruited, how data was screened, and 
				basic information about them. After these two sections, the results used to evaluate 
				reliability and validity are presented. Finally, the conclusions of the pilot study are 
				discussed including consideration of weaknesses of the final measures.
			</p>

			<p>
				<strong><em>Pilot test description.</em></strong> The pilot test consisted of five sections : (1) Participant 
				information survey, (2) a speed of comprehension test, (3) a vocabulary test, (4) the 
				sentence verification task for chapter A, (5) the sentence verification task for chapter B. 
				All sections of the test were delivered electronically via the survey software Qualtrics. 
				Potential participants accessed the test via a secure link and were not supervised during 
				the testing. The link was available during fall quarter, 2012. 
			</p>

			<p>
				The participant information survey asked basic information including age, gender, 
				major, year in college, prior history of brain injury, loss of consciousness, or learning 
				disability. The next two sections were adapted from the <em>Speed and Capacity of Language 
				Processing</em>
				<span class="cite-use" data-ref="0">(<em>SCOLP</em>; Baddeley, Emslie, & Nimmo-Smith, 1992)</span>
				test. The SCOLP 
			</p>

			<div class="pagebreak">
				<span class="pageNumber">
					90
				</span>
			</div>

<!-- Page 91 -->

			<p class="noIndent">
				consists of two separate subtests: (1) the <em>Speed of Comprehension Test</em>, a measure of the 
				rate of information processing, and (2) the <em>Spot the Word</em> test, a measure of word 
				knowledge. The paper version of the test has been validated on a range of individuals 
				from age 16 to 62 from a range of populations including adults with and without acquired 
				brain injury. 
			</p>

			<p>
				The <em>Speed of Comprehension Test</em> subtest was a two-minute timed test that 
				required participants to read a series of sentences and to quickly decide if, based on 
				general world knowledge, was true or false. For example, “Rats have teeth,” would be 
				true but “Desks wear clothes,” would be false. The <em>Spot the Word</em> subtest was an 
				untimed test that required participants to read sixty paired items consisting of a real word 
				and a nonsense word, and to decide which word was the real one. For example, in the 
				pair “kitchen” and “harrick,” the word “kitchen,” would be the real word. 
			</p>

			<p>
				The sentence verification tests for chapters A and B were given in the final two 
				sections. For each chapter participants downloaded a pdf version of the chapter and 
				were asked to read the chapter for ten to fifteen minutes. After reading the chapter, they 
				were asked to spend five minutes to write a few notes about what they learned from the 
				chapter. After five minutes, they were presented with the sentence verification task that 
				consisted of sixty true/false test items. They were given fifteen minutes to answer the 
				questions. The process was repeated with the next chapter. 
			</p>

			<p>
				<strong><em>Pilot participant description.</em></strong> Pilot participants were recruited from a class of 
				students taking an undergraduate introductory course in Communication Disorders and 
				Sciences (CDS). The instructor advised students that completing the pilot test was one of 
				different options for earning extra credit in the course. Participation was voluntary. All 
			</p>

			<div class="pagebreak">
				<span class="pageNumber">
					91
				</span>
			</div>

<!-- Page 92 -->

			<p class="noIndent">
				students were provided with a link to a secure online survey via Qualtrics to access the 
				test. Students who opted to participate clicked a link at the end of the test that took them 
				to a separate survey that gave them the option to enter their name for extra credit; only 
				names given by students were given to the professor of the course. Students’ 
				performance on the test were not linked to their names. 
			</p>

			<p class="noIndent">
				Forty-two responses were recorded. Data were screened to ensure completeness, 
				and to eliminate responses that suggested poor effort. Results of the <em>SCOLP</em> were also 
				screened to identify any participants with below average vocabulary scores, or any 
				participants with a clinically significant discrepancy between the <em>Speed of 
				Comprehension</em> subtest and the vocabulary subtest. A difference of more than four 
				scaled score points would suggest the possibility of a cognitive impairment (Baddeley et 
				al., 1992). 
			</p>

			<p class="noIndent">
				Twelve participants’ data were excluded because they did either not complete all 
				of the tests, or left more than 25% of questions blank on one or both SVT tests. One 
				participant’s data was excluded because she answered “true” to all questions. One 
				participant’s data were excluded because she scored more than two standard deviations 
				below average on the vocabulary test. None of the remaining participants had a 
				discrepancy larger than four scaled score points between the two subtests of the <em>SCOLP</em>. 
			</p>

			<p class="noIndent">
				Data were retained for the twenty-eight participants. The sample included 
				twenty-five women and three males. Age ranged from twenty to forty, with a mean of 23 
				years (SD=6 months). All were CDS majors; thirteen were juniors, one was a senior and 
				thirteen were at the post-baccalaureate level.  
			</p>

			<div class="pagebreak">
				<span class="pageNumber">
					92
				</span>
			</div>

<!-- Page 93 -->

			<p>
				Five self-identified as having a prior concussion or brain injury, six self-identified 
				as having a prior learning disability, and two self-identified as having both a prior 
				concussion or brain injury and a learning disability. Although participants met screening 
				requirements, which included no evidence of cognitive impairment as measured by the 
				<em>SCOLP</em>, group differences could still impact how participants performed on the sentence 
				verification tasks. Therefore participants were coded as belonging to one of three groups: 
				no impairment, ABI or concussion, and learning disability. The two individuals who 
				reported both an ABI and learning disability were included in the ABI group. See Table 
				E.1 for a summary of participants’ scores on the <em>SCOLP</em>.
			</p>

			<p class="noIndent">
				Table E.1 <em>Summary of Speed of Comprehension and Vocabulary Scores</em>
			</p>

			<table class="containerTable topBorder bottomBorder cohesiveCells spreadCells">
				<thead>
					<tr class="bottomBorder">
						<th>
						</th>

						<th>
						</th>

						<th colspan="2">
							Speed of Comprehension
						</th>

						<th colspan="2">
							Vocabulary
						</th>
					</tr>
				</thead>

				<tbody>
					<tr>
						<td>
						</td>

						<td>
						</td>

						<td>
							Raw
						</td>

						<td>
							Scaled Score
						</td>

						<td>
							Raw
						</td>

						<td>
							Scaled Score
						</td>
					</tr>

					<tr>
						<td>
							Total
						</td>

						<td>
							28
						</td>

						<td>
							47.64 (20.57)
						</td>

						<td>
							10.00 (3.00)
						</td>

						<td>
							50.21 (4.65)
						</td>

						<td>
							11.61 (2.70)
						</td>
					</tr>

					<tr>
						<td>
							No dx
						</td>

						<td>
							15
						</td>

						<td>
							46.47 (17.24)
						</td>

						<td>
							9.83 (2.51)
						</td>

						<td>
							51.60 (3.83)
						</td>

						<td>
							11.93 (2.52)
						</td>
					</tr>

					<tr>
						<td>
							ABI
						</td>

						<td>
							7
						</td>

						<td>
							49.57 (25.86)
						</td>

						<td>
							10.28 (3.77)
						</td>

						<td>
							50.00 (5.03)
						</td>

						<td>
							12.00 (3.06)
						</td>
					</tr>

					<tr>
						<td>
							LD
						</td>

						<td>
							6
						</td>

						<td>
							48.33 (25.29)
						</td>

						<td>
							10.10 (3.68)
						</td>

						<td>
							47.00 (5.22)
						</td>

						<td>
							10.33 (2.81)
						</td>
					</tr>
				</tbody>
			</table>

			<p class="caption noIndent">
				<em>Note.</em>  Raw scores for speed of processing represent the number of accurately answered items within two 
				minutes from a possible one hundred items. Scaled scores for speed of processing were derived based on
			</p>

			<div class="pagebreak">
				<span class="pageNumber">
					93
				</span>
			</div>

<!-- Page 94 -->

			<p class="caption noIndent">
				the sample. Raw scores for vocabulary are the number of correctly identified words from 60 real word + 
				nonsense word pairs. Scaled scores for vocabulary were based on published norms (Baddeley et al., 1992).
			</p>

			<p>
				<strong>Pilot Reliability.</strong> The distribution of scores for the raw tests was roughly normal 
				for the all score categories. See Figures E.1 and E.2. Examination of the distribution of 
				item difficulty across the three sentence types indicated distribution was roughly 
				equivalent across the paraphrase sentence types. However, the distributions were uneven 
				across the other two sentence types, particularly for the local sentences. Item trimming 
				was conducted to improve distribution. 
			</p>

			<p>
				To determine whether there were significant correlations between Chapter A test 
				scores and Chapter B test scores, Pearson’s correlation statistic was conducted. 
				Correlations were significant for between chapter comparisons for total scores (<em>r</em>=.816, p
				< .05). Finally a regression analysis was conducted to determine if vocabulary scores 
				from the SCOLP predicted overall scores on the combined SVTs. The result was 
				significant (<em>r</em>=.008, <em>p</em>=.05). 
			</p>

			<figure>
				<img src="/contents/dissertation/images/figureE1.png">

				<p>
					Figure E.1: <em>Frequency of participants’ total percentage scores for chapters A and B.</em>
				</p>
			</figure>

			<div class="pagebreak">
				<span class="pageNumber">
					94
				</span>
			</div>

<!-- Page 95 -->

			<figure>
				<img src="/contents/dissertation/images/figureE2.png">

				<p>
					Figure E.2: <em>Frequency of participants’ subtotal scores by sentence types for chapters A and B.</em>
				</p>

			<div class="pagebreak">
				<span class="pageNumber">
					95
				</span>
			</div>

<!-- Page 96 -->

			<p class="noIndent">
				Table E.3
			</p>

			<p class="noIndent">
				Map of Item Difficulty by Item Type for Each Chapter
			</p>

			<figure>
				<img src="/contents/dissertation/images/tableE3.png">
			</figure>

			<div class="pagebreak">
				<span class="pageNumber">
					96
				</span>
			</div>

<!-- Page 97 -->

			<p>
				Overall, the analysis of results indicates the two sentence verification tests were 
				grossly equivalent. Distributions of scores were normal and item difficulties were evenly 
				distributed across chapters. The correlation results also indicated that how a participant 
				performed on one of the sentence verification tests was significantly correlated with how 
				that participant performed on the other test; this finding was true for overall scores and 
				subtotals based on the three types of sentences. 
			</p>

			<p>
				See Table E.3 for a summary of scores for each test and subtest. For descriptive 
				purposes, the table includes scores by participant category as well. Note results of 
				ANOVAs conducted to compare performance by participant category did not indicate 
				any significant differences. 
			</p>

			<p class="noIndent">
				Table E.3
			</p>

			<p class="noIndent">
				<em>Summary of Scores by Sentence Type for each Chapter by Participant Category</em>
			</p>

			<table class="containerTable bottomBorder topBorder spreadCells cohesiveCells">
				<thead>
					<tr>
						<th>
						</th>

						<th>
						</th>

						<th colspan="2" class="bottomBorder">
							All (<em>n</em>=28)
						</th>

						<th colspan="2" class="bottomBorder">
							No Dx <br />
							(<em>n</em>=15)
						</th>

						<th colspan="2" class="bottomBorder">
							ABI (<em>n</em>=7)
						</th>

						<th colspan="2" class="bottomBorder">
							LD (<em>n</em>=6)
						</th>
					</tr>

					<tr>
						<th>
						</th>

						<th>
						</th>

						<th>
							A
						</th>

						<th>
							B
						</th>

						<th>
							A
						</th>

						<th>
							B
						</th>

						<th>
							A
						</th>

						<th>
							B
						</th>

						<th>
							A
						</th>

						<th>
							B
						</th>
				</thead>

				<tbody>
					<tr class="topBorder">
						<td>
							Total
						</td>

						<td>
							X
						</td>

						<td>
							66.9
						</td>

						<td>
							63.4
						</td>

						<td>
							67.0
						</td>

						<td>
							65.4
						</td>

						<td>
							66.4
						</td>

						<td>
							63.8
						</td>

						<td>
							67.0
						</td>

						<td>
							57.8
						</td>
					</tr>

					<tr>
						<td>
						</td>

						<td>
							SD
						</td>

						<td>
							15.5
						</td>

						<td>
							12.5
						</td>

						<td>
							16.3
						</td>

						<td>
							14.2
						</td>

						<td>
							19.8
						</td>

						<td>
							11.3
						</td>

						<td>
							9.3
						</td>

						<td>
							8.73
						</td>
					</tr>

					<tr>
						<td>							
							Paraphrase
						</td>

						<td>
							X
						</td>

						<td>
							68.7
						</td>

						<td>
							65.1
						</td>

						<td>
							68.6
						</td>

						<td>
							69.3
						</td>

						<td>
							68.3
						</td>

						<td>
							58.6
						</td>

						<td>
							69.0
						</td>

						<td>
							62.2
						</td>
					</tr>

					<tr>
						<td>
						</td>

						<td>
							SD
						</td>

						<td>
							15.7
						</td>

						<td>
							16.0
						</td>

						<td>
							16.4
						</td>

						<td>
							14.8
						</td>

						<td>
							19.3
						</td>

						<td>
							19.8
						</td>

						<td>
							11.4
						</td>

						<td>
							10.3
						</td>
					</tr>

					<tr>
						<td>
							Local
						</td>

						<td>
							X
						</td>

						<td>
							68.2
						</td>

						<td>
						 67.6
						</td>

						<td>
							73.8
						</td>

						<td>
							69.5
						</td>

						<td>
							60.5
						</td>

						<td>
							73.5
						</td>

						<td>
							63.3
						</td>

						<td>
							60.0
						</td>
					</tr>

					<tr>
						<td>
						</td>

						<td>
							SD
						</td>

						<td>
							18.5
						</td>

						<td>
							15.9
						</td>

						<td>
							18.3
						</td>

						<td>
							16.3
						</td>

						<td>
							22.9
						</td>

						<td>
							12.8
						</td>

						<td>
							8.2
						</td>

						<td>
							11.4
						</td>
					</tr>

					<tr>
						<td>
							Global
						</td>

						<td>
							X
						</td>

						<td>
							61.6
						</td>

						<td>
							56.5
						</td>

						<td>
							56.7
						</td>

						<td>
							54.6
						</td>

						<td>
							67.9
						</td>

						<td>
							65.2
						</td>

						<td>
							66.7
						</td>

						<td>
							51.0
						</td>
					</tr>

					<tr>
						<td>
						</td>

						<td>
							SD
						</td>

						<td>
							21.0
						</td>

						<td>
							15.7
						</td>

						<td>
							18.5
						</td>

						<td>
							19.0
						</td>

						<td>
							29.0
						</td>

						<td>
							4.9
						</td>

						<td>
							15.6
						</td>

						<td>
							11.5
						</td>
					</tr>
				</tbody>
			</table>

			<div class="pagebreak">
				<span class="pageNumber">
					97
				</span>
			</div>

		</section> <!-- Section 0 -->

	</div> <!-- /container -->

</body>
</html>